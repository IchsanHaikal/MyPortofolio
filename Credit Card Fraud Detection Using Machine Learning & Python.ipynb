{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31feb217",
   "metadata": {},
   "source": [
    "**About the data**\n",
    "\n",
    "The data for this article can be found here. This dataset contains the real bank transactions made by European cardholders in the year 2013. As a security concern, the actual variables are not being shared but — they have been transformed versions of PCA. As a result, we can find 29 feature columns and 1 final class column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81314b43",
   "metadata": {},
   "source": [
    ">**Tentang data**\n",
    "\n",
    ">Data untuk artikel ini dapat ditemukan di sini. Dataset ini berisi transaksi bank nyata yang dilakukan oleh pemegang kartu Eropa pada tahun 2013. Sebagai masalah keamanan, variabel sebenarnya tidak dibagikan tetapi — mereka telah mengubah versi PCA. Hasilnya, kita dapat menemukan 29 kolom fitur dan 1 kolom kelas akhir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da218989",
   "metadata": {},
   "source": [
    "**Importing Necessary Libraries**\n",
    "\n",
    "It is a good practice to import all the necessary libraries in one place — so that we can modify them quickly.\n",
    "For this credit card data, the features that we have in the dataset are the transformed version of PCA, so we will not need to perform the feature selection again. Otherwise, it is recommended to use RFE, RFECV, SelectKBest and VIF score to find the best features for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ae13b",
   "metadata": {},
   "source": [
    ">**Mengimpor library yang Diperlukan**\n",
    "\n",
    ">Ini adalah praktik yang baik untuk mengimpor semua perpustakaan yang diperlukan di satu tempat — sehingga kami dapat memodifikasinya dengan cepat. Untuk data kartu kredit ini, fitur yang kita miliki dalam dataset adalah versi PCA yang diubah, jadi kita tidak perlu melakukan pemilihan fitur lagi. Jika tidak, disarankan untuk menggunakan skor RFE, RFECV, SelectKBest, dan VIF untuk menemukan fitur terbaik untuk model Anda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5f10c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Packages related to general operating system & warnings\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Packages related to data importing, manipulation, exploratory data #analysis, data understanding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from termcolor import colored as cl # text customization\n",
    "\n",
    "#Packages related to data visualizaiton\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Setting plot sizes and type of plot\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.gray()\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import  PolynomialFeatures, KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa as tsa\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz, export_text\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor \n",
    "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c5327",
   "metadata": {},
   "source": [
    "**Importing Dataset**\n",
    "\n",
    "Importing the dataset is pretty much simple. You can use pandas module in python to import it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd2ceb",
   "metadata": {},
   "source": [
    ">**Mengimpor Dataset**\n",
    "\n",
    ">Mengimpor dataset cukup sederhana. Anda dapat menggunakan modul pandas dengan python untuk mengimpornya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebf1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"creditcardpy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1075fa",
   "metadata": {},
   "source": [
    "**Data Processing & Understanding**\n",
    "\n",
    "The one main thing you will notice about this data is that — the dataset is imbalanced towards a feature. Which seems pretty valid for such kind of data. Because today many banks have adopted different security mechanisms — so it is harder for hackers to make such moves.\n",
    "\n",
    "Still, sometimes when there is some vulnerability in the system — the chance of such activities can increase.\n",
    "\n",
    "That’s why we can see the majority of transactions belongs to our datasets are normal and only a few percentages of transactions are fraudulent.\n",
    "\n",
    "Let’s check the transaction distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48aa405",
   "metadata": {},
   "source": [
    ">**Pengolahan Data & Pemahaman**\n",
    "\n",
    ">Satu hal utama yang akan Anda perhatikan tentang data ini adalah bahwa — dataset tidak seimbang terhadap suatu fitur. Yang tampaknya cukup valid untuk data semacam itu. Karena saat ini banyak bank telah mengadopsi mekanisme keamanan yang berbeda — sehingga lebih sulit bagi peretas untuk melakukan langkah seperti itu.\n",
    "\n",
    ">Namun, kadang — kadang ketika ada beberapa kerentanan dalam sistem-kemungkinan kegiatan tersebut dapat meningkat.\n",
    "\n",
    ">Itu sebabnya kita dapat melihat sebagian besar transaksi milik dataset kita normal dan hanya beberapa persentase transaksi yang curang.\n",
    "\n",
    ">Mari kita periksa distribusi transaksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8277f2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTotal number of Transactions are 284807\u001b[0m\n",
      "\u001b[1mNumber of Normal Transactions are 284315\u001b[0m\n",
      "\u001b[1mNumber of fraudulent Transactions are 492\u001b[0m\n",
      "\u001b[1mPercentage of fraud Transactions is 0.17\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Total_transactions = len(data)\n",
    "normal = len(data[data.Class == 0])\n",
    "fraudulent = len(data[data.Class == 1])\n",
    "fraud_percentage = round(fraudulent/normal*100, 2)\n",
    "print(cl('Total number of Transactions are {}'.format(Total_transactions), attrs = ['bold']))\n",
    "print(cl('Number of Normal Transactions are {}'.format(normal), attrs = ['bold']))\n",
    "print(cl('Number of fraudulent Transactions are {}'.format(fraudulent), attrs = ['bold']))\n",
    "print(cl('Percentage of fraud Transactions is {}'.format(fraud_percentage), attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb28e4",
   "metadata": {},
   "source": [
    "Only 0.17% of transactions are fraudulent.\n",
    "\n",
    "We can also check for null values using the following line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015cd22",
   "metadata": {},
   "source": [
    ">Hanya 0,17% transaksi yang curang.\n",
    "\n",
    ">Kami juga dapat memeriksa nilai nol menggunakan baris kode berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02cada0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48acb8",
   "metadata": {},
   "source": [
    "As per the count per column, we have no null values. Also, feature selection is not the case for this use case. Anyway, you can try applying feature selection mechanisms to check if the results are optimised.\n",
    "\n",
    "I have observed in our data 28 features are transformed versions of PCA but the Amount is the original one. And, while checking the minimum and maximum is in the amount — I found the difference is huge that can deviate our result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1dee2",
   "metadata": {},
   "source": [
    ">Sesuai hitungan per kolom, kami tidak memiliki nilai nol. Selain itu, pemilihan fitur tidak berlaku untuk kasus penggunaan ini. Bagaimanapun, Anda dapat mencoba menerapkan mekanisme pemilihan fitur untuk memeriksa apakah hasilnya dioptimalkan.\n",
    "\n",
    ">Saya telah mengamati dalam data kami 28 fitur adalah versi PCA yang diubah tetapi jumlahnya adalah yang asli. Dan, saat memeriksa minimum dan maksimum dalam jumlah — saya menemukan perbedaannya sangat besar yang dapat menyimpang hasil kami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c76af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 25691.16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data.Amount),max(data.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609700b4",
   "metadata": {},
   "source": [
    "In this case, it is a good practice to scale this variable. We can use a standard scaler to make it fix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1dc1a",
   "metadata": {},
   "source": [
    ">Dalam hal ini, merupakan praktik yang baik untuk menskalakan variabel ini. Kita dapat menggunakan scaler standar untuk memperbaikinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6f750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "amount = data['Amount'].values\n",
    "data['Amount'] = sc.fit_transform(amount.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a6c42",
   "metadata": {},
   "source": [
    "We have one more variable which is the time which can be an external deciding factor — but in our modelling process, we can drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26546820",
   "metadata": {},
   "source": [
    ">Kami memiliki satu variabel lagi yaitu waktu yang dapat menjadi faktor penentu eksternal — tetapi dalam proses pemodelan kami, kami dapat menjatuhkannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648998d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56549d",
   "metadata": {},
   "source": [
    "We can also check for any duplicate transactions. Before removing any duplicate transaction, we are having 284807 transactions in our data. Let’s remove the duplicate and observe the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62933331",
   "metadata": {},
   "source": [
    ">Kami juga dapat memeriksa transaksi duplikat. Sebelum menghapus transaksi duplikat, kami memiliki 284807 transaksi dalam data kami. Mari kita hapus duplikat dan amati perubahannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad8424dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64ca9a",
   "metadata": {},
   "source": [
    "Run the below line of code to remove any duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e6dcb8",
   "metadata": {},
   "source": [
    ">Jalankan baris kode di bawah ini untuk menghapus duplikat apa pun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec4b9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c6b23d",
   "metadata": {},
   "source": [
    "Let’s now check the count again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b82f53e",
   "metadata": {},
   "source": [
    ">Sekarang mari kita periksa hitungannya lagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01cffe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde54c6",
   "metadata": {},
   "source": [
    "So, we were having around ~9000 duplicate transactions.\n",
    "\n",
    "Here we go!! We now have properly scaled data with no duplicate, no missing. Let’s now split it for our model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b43cdac",
   "metadata": {},
   "source": [
    ">Jadi, kami memiliki sekitar ~9000 transaksi duplikat.\n",
    "\n",
    ">Ini dia!! Kami sekarang memiliki data yang diskalakan dengan benar tanpa duplikat, tidak ada yang hilang. Sekarang mari kita membaginya untuk bangunan model kita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c59c9",
   "metadata": {},
   "source": [
    "**Train & Test Split**\n",
    "\n",
    "Before splitting train & test — we need to define dependent and independent variables. The dependent variable is also known as X and the independent variable is known as y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93c834",
   "metadata": {},
   "source": [
    ">**Latih & Uji Split**\n",
    "\n",
    ">Sebelum memisahkan train & test - kita perlu mendefinisikan variabel dependen dan independen. Variabel dependen juga dikenal sebagai X dan variabel independen dikenal sebagai y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8467eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1).values\n",
    "y = data['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4af8f",
   "metadata": {},
   "source": [
    "Now, let split our train and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27e206",
   "metadata": {},
   "source": [
    ">Sekarang, mari kita membagi data kereta dan uji kami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a07f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44049119",
   "metadata": {},
   "source": [
    "That’s it. We now have two different data set — Train data we will be used for training our model and the data which is unseen will be used for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e9b48",
   "metadata": {},
   "source": [
    ">Itu saja. Kami sekarang memiliki dua kumpulan data yang berbeda-Data latih yang akan kami gunakan untuk melatih model kami dan data yang tidak terlihat akan digunakan untuk pengujian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91955566",
   "metadata": {},
   "source": [
    "**Model Building**\n",
    "\n",
    "We will be trying different machine learning models one by one. Defining models are much easier. A single line of code can define our model. And, in the same way, a single line of code can fit the model on our data.\n",
    "\n",
    "We can also tune these models by selecting different optimized parameters. But, if the accuracy is better even with less parameter tuning then — no need to make it complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93028f37",
   "metadata": {},
   "source": [
    ">**Bangun Model**\n",
    "\n",
    ">Kami akan mencoba model pembelajaran mesin yang berbeda satu per satu. Mendefinisikan model jauh lebih mudah. Satu baris kode dapat menentukan model kita. Dan, dengan cara yang sama, satu baris kode dapat memuat model pada data kami.\n",
    "\n",
    ">Kami juga dapat menyetel model ini dengan memilih parameter yang dioptimalkan berbeda. Tetapi, jika akurasinya lebih baik bahkan dengan penyetelan parameter yang lebih sedikit maka — tidak perlu membuatnya rumit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e983f",
   "metadata": {},
   "source": [
    "***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3121cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "dt_yhat = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7b45f",
   "metadata": {},
   "source": [
    "Let’s check the accuracy of our decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acafeba9",
   "metadata": {},
   "source": [
    ">Mari kita periksa keakuratan model decision tree kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f127a356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Decision Tree model is 0.9991293748911718\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, dt_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93659b02",
   "metadata": {},
   "source": [
    "Checking F1-Score for the decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a0e30",
   "metadata": {},
   "source": [
    ">Memeriksa Skor F1 untuk model decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5045b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the Decision Tree model is 0.7435897435897436\n"
     ]
    }
   ],
   "source": [
    "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, dt_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204374a",
   "metadata": {},
   "source": [
    "Checking the confusion matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f2477",
   "metadata": {},
   "source": [
    ">Memeriksa matriks kebingungan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "525f11b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68769,    19],\n",
       "       [   41,    87]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, dt_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c373b",
   "metadata": {},
   "source": [
    "Here, the first row represents positive and the second row represents negative. So, we have 68782 as true positive and 18 are false positive. That says, out of 68782+18=68800, we have 68782 that are successfully classified as a normal transaction and 18 were falsely classified as normal — but they were fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce96b11",
   "metadata": {},
   "source": [
    ">Di sini, baris pertama mewakili positif dan baris kedua mewakili negatif. Jadi, kita memiliki 68782 sebagai positif sejati dan 18 adalah positif palsu. Yang mengatakan, dari 68782 + 18 = 68800, kami memiliki 68782 yang berhasil diklasifikasikan sebagai transaksi normal dan 18 salah diklasifikasikan sebagai normal — tetapi mereka curang."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e39e23",
   "metadata": {},
   "source": [
    "Let’s now try different models and check their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a2a0f",
   "metadata": {},
   "source": [
    ">Sekarang mari kita coba model yang berbeda dan periksa kinerjanya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b741ee",
   "metadata": {},
   "source": [
    "***K-Nearest Neighbors***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13371e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_yhat = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227b7a4",
   "metadata": {},
   "source": [
    "Let’s check the accuracy of our K-Nearest Neighbors model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa914c",
   "metadata": {},
   "source": [
    ">Mari kita periksa keakuratan model K-Nearest Neighbors kami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cdee710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the K-Nearest Neighbors model is 0.999288989494457\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d4d5f9",
   "metadata": {},
   "source": [
    "Checking F1-Score for the K-Nearest Neighbors model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856f99d",
   "metadata": {},
   "source": [
    ">Memeriksa F1-Skor untuk model K-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a46839ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the K-Nearest Neighbors model is 0.7949790794979079\n"
     ]
    }
   ],
   "source": [
    "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa5fc9",
   "metadata": {},
   "source": [
    "***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98253fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b421b6",
   "metadata": {},
   "source": [
    "Let’s check the accuracy of our Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d37f9",
   "metadata": {},
   "source": [
    ">Mari kita periksa keakuratan model Logistic Regression kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf79e1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Logistic Regression model is 0.9989552498694062\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793640f0",
   "metadata": {},
   "source": [
    "Checking F1-Score for the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce66b4",
   "metadata": {},
   "source": [
    ">Memeriksa Skor F1 untuk model Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b5a4952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the Logistic Regression model is 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8fb3b",
   "metadata": {},
   "source": [
    "***Support Vector Machines***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95d876f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_yhat = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ddca7",
   "metadata": {},
   "source": [
    "Let’s check the accuracy of our Support Vector Machines model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6f12f",
   "metadata": {},
   "source": [
    ">Mari kita periksa keakuratan model Support Vector Machines kami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54eea504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Support Vector Machines model is 0.999318010331418\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the Support Vector Machines model is {}'.format(accuracy_score(y_test, svm_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134d17a",
   "metadata": {},
   "source": [
    "Checking F1-Score for the Support Vector Machines model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d720d",
   "metadata": {},
   "source": [
    ">Memeriksa Skor F1 untuk model Support Vector Machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b69d0689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the Support Vector Machines model is 0.7813953488372093\n"
     ]
    }
   ],
   "source": [
    "print('F1 score of the Support Vector Machines model is {}'.format(f1_score(y_test, svm_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf583a2",
   "metadata": {},
   "source": [
    "***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f98da827",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78b0ee",
   "metadata": {},
   "source": [
    "Let’s check the accuracy of our Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35668fcb",
   "metadata": {},
   "source": [
    ">Mari kita periksa keakuratan model Random Forest kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9b11c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Random Forest model is 0.9991293748911718\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the Random Forest model is {}'.format(accuracy_score(y_test, rf_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb39a1",
   "metadata": {},
   "source": [
    "Checking F1-Score for the Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fddb8b",
   "metadata": {},
   "source": [
    ">Memeriksa Skor F1 untuk model Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71657e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the Random Forest model is 0.724770642201835\n"
     ]
    }
   ],
   "source": [
    "print('F1 score of the Random Forest model is {}'.format(f1_score(y_test, rf_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0b88a",
   "metadata": {},
   "source": [
    "***XGBoost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42023b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:55:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth = 4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d8039",
   "metadata": {},
   "source": [
    "Let’s check the accuracy of our XGBoost model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94cd210",
   "metadata": {},
   "source": [
    ">Mari kita periksa keakuratan model XGBoost kami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fef1f030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the XGBoost model is 0.999506645771664\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182bd382",
   "metadata": {},
   "source": [
    "Checking F1-Score for the XGBoost model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd346ea0",
   "metadata": {},
   "source": [
    ">Memeriksa Skor F1 untuk model XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1697f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the XGBoost model is 0.8495575221238937\n"
     ]
    }
   ],
   "source": [
    "print('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34957eb3",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Well, congratulation!! We just received 99.95% accuracy in our credit card fraud detection. This number should not be surprising as our data was balanced towards one class. The good thing that we have noticed from the confusion matrix is that — our model is not overfitted.\n",
    "\n",
    "Finally, based on our accuracy score — XGBoost is the winner for our case. The only catch here is the data that we have received for model training. The data features are the transformed version of PCA. If the actual features follow a similar pattern then we are doing great!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c0407",
   "metadata": {},
   "source": [
    ">**Kesimpulan**\n",
    "\n",
    ">Nah, selamat!! Kami baru saja menerima akurasi 99,95% dalam deteksi penipuan kartu kredit kami. Jumlah ini seharusnya tidak mengejutkan karena data kami seimbang terhadap satu kelas. Hal baik yang kami perhatikan dari matriks kebingungan adalah bahwa — model kami tidak overfitted.\n",
    "\n",
    ">Akhirnya, berdasarkan skor akurasi kami-XGBoost adalah pemenang untuk kasus kami. Satu-satunya tangkapan di sini adalah data yang kami terima untuk pelatihan model. Fitur data adalah versi PCA yang diubah. Jika fitur yang sebenarnya mengikuti pola yang sama maka kita lakukan besar!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
